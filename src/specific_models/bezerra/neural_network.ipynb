{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set Bezerra - NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MC_L.csv', 'MC_I1.csv', 'MC_I2.csv', 'MC_I3.csv']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\n",
    "DEVICE = 'GPU/:0'\n",
    "\n",
    "DATASET_DIR = '../datasets/Dataset-IoT/'\n",
    "NETFLOW_DIR = DATASET_DIR + 'MC/NetFlow/'\n",
    "\n",
    "# MC_I_FIRST: Has infected data by Hajime, Aidra and BashLite botnets'\n",
    "# MC_I_SECOND: Has infected data from Mirai botnets\n",
    "# MC_I_THIR: Has infected data from Mirai, Doflo, Tsunami and Wroba botnets\n",
    "# MC_L: Has legitimate data, no infection\n",
    "MC_L = r'MC_L.csv'\n",
    "\n",
    "data_set_files = [r'MC_I{}.csv'.format(index) for index in range(1, 4)]\n",
    "data_set_files.insert(0, r'MC_L.csv')\n",
    "print (data_set_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data set into a pd DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>td</th>\n",
       "      <th>sp</th>\n",
       "      <th>dp</th>\n",
       "      <th>fwd</th>\n",
       "      <th>stos</th>\n",
       "      <th>ipkt</th>\n",
       "      <th>ibyt</th>\n",
       "      <th>opkt</th>\n",
       "      <th>obyt</th>\n",
       "      <th>...</th>\n",
       "      <th>smk</th>\n",
       "      <th>dmk</th>\n",
       "      <th>dtos</th>\n",
       "      <th>dir</th>\n",
       "      <th>svln</th>\n",
       "      <th>dvln</th>\n",
       "      <th>cl</th>\n",
       "      <th>sl</th>\n",
       "      <th>al</th>\n",
       "      <th>exid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>360617.000000</td>\n",
       "      <td>3.606170e+05</td>\n",
       "      <td>360617.000000</td>\n",
       "      <td>360617.000000</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.000000</td>\n",
       "      <td>3.606170e+05</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>...</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "      <td>360617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.994440</td>\n",
       "      <td>7.012068e+02</td>\n",
       "      <td>31020.098026</td>\n",
       "      <td>2121.932535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.185163</td>\n",
       "      <td>2.208133e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074357</td>\n",
       "      <td>2.437678e+04</td>\n",
       "      <td>19846.547700</td>\n",
       "      <td>9340.086984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.643406</td>\n",
       "      <td>2.208847e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>13529.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>31443.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>48105.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.502610e+06</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96808.000000</td>\n",
       "      <td>7.923012e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Label            td             sp             dp       fwd  \\\n",
       "count  360617.000000  3.606170e+05  360617.000000  360617.000000  360617.0   \n",
       "mean        0.994440  7.012068e+02   31020.098026    2121.932535       0.0   \n",
       "std         0.074357  2.437678e+04   19846.547700    9340.086984       0.0   \n",
       "min         0.000000  0.000000e+00       0.000000       0.000000       0.0   \n",
       "25%         1.000000  0.000000e+00   13529.000000      23.000000       0.0   \n",
       "50%         1.000000  0.000000e+00   31443.000000      23.000000       0.0   \n",
       "75%         1.000000  0.000000e+00   48105.000000      81.000000       0.0   \n",
       "max         1.000000  3.502610e+06   65535.000000   65535.000000       0.0   \n",
       "\n",
       "           stos           ipkt          ibyt      opkt      obyt  ...  \\\n",
       "count  360617.0  360617.000000  3.606170e+05  360617.0  360617.0  ...   \n",
       "mean        0.0       4.185163  2.208133e+03       0.0       0.0  ...   \n",
       "std         0.0     274.643406  2.208847e+05       0.0       0.0  ...   \n",
       "min         0.0       1.000000  2.000000e+01       0.0       0.0  ...   \n",
       "25%         0.0       1.000000  4.000000e+01       0.0       0.0  ...   \n",
       "50%         0.0       1.000000  4.000000e+01       0.0       0.0  ...   \n",
       "75%         0.0       1.000000  4.000000e+01       0.0       0.0  ...   \n",
       "max         0.0   96808.000000  7.923012e+07       0.0       0.0  ...   \n",
       "\n",
       "            smk       dmk      dtos       dir      svln      dvln        cl  \\\n",
       "count  360617.0  360617.0  360617.0  360617.0  360617.0  360617.0  360617.0   \n",
       "mean        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "std         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "min         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "25%         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "50%         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "75%         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "max         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "             sl        al      exid  \n",
       "count  360617.0  360617.0  360617.0  \n",
       "mean        0.0       0.0       1.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       1.0  \n",
       "25%         0.0       0.0       1.0  \n",
       "50%         0.0       0.0       1.0  \n",
       "75%         0.0       0.0       1.0  \n",
       "max         0.0       0.0       1.0  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legitimate_file_path = NETFLOW_DIR + MC_L\n",
    "\n",
    "LABEL_COLUMN = 'Label'\n",
    "\n",
    "#reading data\n",
    "df = pd.read_csv (legitimate_file_path)\n",
    "\n",
    "# for file in data_set_files:\n",
    "#     aux_df = pd.read_csv(NETFLOW_DIR + file)\n",
    "#     df = pd.concat([df, aux_df], ignore_index=True)\n",
    "\n",
    "aux_df = pd.read_csv(NETFLOW_DIR + data_set_files[1])\n",
    "df = pd.concat([df, aux_df], ignore_index=True)\n",
    "\n",
    "#making the final DataFrame\n",
    "df = df.sample(frac=1, random_state=math.ceil(time.time()), )\n",
    "df = df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230794 train examples\n",
      "57699 validation examples\n",
      "72124 test examples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split (df, test_size=0.2)\n",
    "train, val = train_test_split (train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "358612\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(df['Label'])\n",
    "print (neg)\n",
    "print (pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame to tf.data.Dataset object\n",
    "def df_to_dataset(dataFrame, shuffle=True, batch_size=32):\n",
    "    print(dataFrame)\n",
    "    dataFrame = dataFrame.copy()\n",
    "    labels = dataFrame.pop(LABEL_COLUMN)\n",
    "    data_set = tf.data.Dataset.from_tensor_slices((dict(dataFrame), labels))\n",
    "    if shuffle:\n",
    "        data_set = data_set.shuffle(buffer_size=len(dataFrame))\n",
    "    data_set = data_set.batch(batch_size)\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "type(train)\n",
    "for key in train.columns:\n",
    "    print(type(train[key]))\n",
    "# train_ds = df_to_dataset(train, batch_size=BATCH_SIZE)\n",
    "# val_ds = df_to_dataset(val, shuffle=False, batch_size=BATCH_SIZE)\n",
    "# test_ds = df_to_dataset(test, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Feature Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "cat_cols, num_cols = df.columns[df.dtypes == 'O'], df.columns[df.dtypes != 'O']\n",
    "num_cols = num_cols[1:]\n",
    "\n",
    "#numeric columns\n",
    "for key in num_cols:\n",
    "    feature_columns.append(feature_column.numeric_column(key))\n",
    "\n",
    "\n",
    "#categorical columns\n",
    "all_categories = [df[column].unique() for column in df[cat_cols]]\n",
    "for item, categories in zip(cat_cols, all_categories):\n",
    "    feature = feature_column.categorical_column_with_vocabulary_list(item, categories)\n",
    "    mfeature = feature_column.embedding_column (feature, dimension=8)\n",
    "    feature_columns.append(mfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "hidden_layer_size, num_classes = 128, 1\n",
    "layers = [\n",
    "    feature_layer,\n",
    "    tf.keras.layers.Dense(hidden_layer_size, use_bias=True, activation='relu', kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,  use_bias=True, activation='relu', kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,  use_bias=True, activation='relu', kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(num_classes,  use_bias=True, kernel_initializer=initializer),\n",
    "]\n",
    "\n",
    "optimizer = keras.optimizer.Adam('')\n",
    "model = tf.keras.Sequential(layers)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "16843/16843 [==============================] - 915s 54ms/step - loss: 15.6381 - accuracy: 0.9909 - val_loss: 0.0463 - val_accuracy: 0.9941\n",
      "Epoch 2/5\n",
      "16843/16843 [==============================] - 919s 55ms/step - loss: 0.0583 - accuracy: 0.9937 - val_loss: 0.0354 - val_accuracy: 0.9943\n",
      "Epoch 3/5\n",
      "16843/16843 [==============================] - 915s 54ms/step - loss: 0.0394 - accuracy: 0.9940 - val_loss: 0.0353 - val_accuracy: 0.9943\n",
      "Epoch 4/5\n",
      "16843/16843 [==============================] - 920s 55ms/step - loss: 0.8077 - accuracy: 0.9942 - val_loss: 0.0355 - val_accuracy: 0.9942\n",
      "Epoch 5/5\n",
      "16843/16843 [==============================] - 904s 54ms/step - loss: 0.0374 - accuracy: 0.9939 - val_loss: 0.0360 - val_accuracy: 0.9942\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "with tf.device (DEVICE):\n",
    "    model.fit(train_ds, \n",
    "              epochs=5, \n",
    "              validation_data=val_ds, \n",
    "              callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1f95908fcbf4c718\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1f95908fcbf4c718\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
